# Bot Factory

A reusable RAG chatbot framework. Write a config, run one command, get a working chatbot with semantic search, Claude-powered responses, and a themed frontend.

## How It Works

Each bot is a folder under `bots/` containing three things: a config file, a system prompt, and knowledge data. The factory's core modules handle everything else â€” chunking data into text, generating OpenAI embeddings, storing them in DynamoDB, retrieving relevant context via cosine similarity, and generating Claude responses.

The backend auto-discovers any bot with `enabled: true` in its config and registers API endpoints automatically. No code changes needed.

```
User question
  â†’ OpenAI embedding (convert question to vector)
  â†’ DynamoDB cosine search (find relevant knowledge)
  â†’ Claude Sonnet (generate response with context)
  â†’ User gets answer
```

## Prerequisites

Dependencies (PyYAML, numpy, openai, anthropic, etc.) are installed inside the Docker container automatically. You don't need to install them on your host machine.

You'll need:

- **Docker** â€” for local development (`docker compose up -d`)
- **AWS CLI** â€” configured with credentials for DynamoDB and S3

Claude Integration (Skip if you are intending to use Bedrock)

- **OpenAI API key** â€” set as `OPENAI_API_KEY` environment variable (for embeddings)
- **Anthropic API key** â€” set as `ANTHROPIC_API_KEY` environment variable (for Claude responses)

Bedrock
After you make your first call to bedrock, you'll need to do the following to continue.

- Go to the AWS Console:
- Bedrock â†’ Model catalog (or Model access)
- There should be a prompt to submit use case details. Mine was at the top of the page.
- Fill it out â€” keep it simple ("AI chatbot for personal portfolio website")

## Creating a New Bot

### Step 1: Create the bot folder

Pick a bot ID. This ID drives everything â€” folder names, API endpoints, HTML filenames.

```
ai/factory/bots/{bot_id}/
```

Example:

```bash
mkdir -p ai/factory/bots/cooking
```

### Step 2: Write config.yml

This is the single source of truth for your bot. It configures the backend (model, RAG settings, boundaries) and the frontend (page title, nav, suggestions).

```yaml
bot:
  id: "cooking"
  enabled: true
  name: "ChefBot"
  personality: "friendly"

  response_style:
    tone: "conversational"
    length: "concise"
    suggestions: true

  model:
    provider: "anthropic"
    name: "claude-sonnet-4-20250514"
    max_tokens: 1000

  rag:
    embedding_model: "openai"
    top_k: 5
    similarity_threshold: 0.3

  boundaries:
    discuss_cooking: true
    discuss_unrelated: false

suggestions:
  - "How do I make pasta from scratch?"
  - "What temp for a medium-rare steak?"
  - "Best way to dice an onion?"

frontend:
  subtitle: "Your Kitchen Assistant"
  welcome: "Hey! Ask me anything about cooking."
  placeholder: "Ask about cooking..."
  badge: "Beta"
  nav:
    - icon: "ğŸ³"
      label: "Chat"
      section: "chat"
    - icon: "ğŸ¥©"
      label: "Proteins"
      section: "proteins"
```

See [Config Reference](#config-reference) for all fields.

### Step 3: Write prompt.yml

This is the system prompt sent to Claude with every request. It defines personality, rules, and response formatting. The `prompt` field supports `{current_date}` as a placeholder that gets injected at runtime.

```
ai/factory/bots/{bot_id}/prompt.yml
```

Example:

```yaml
prompt: |
  You are ChefBot, a friendly cooking assistant.

  Today's date is {current_date}.

  Rules:
  - Keep responses to 2-3 sentences
  - Always mention food safety when relevant
  - If asked about something outside cooking, politely redirect
```

### Step 4: Add knowledge data

Create YAML files in the `data/` folder using the universal data format.

```
ai/factory/bots/{bot_id}/data/
```

Two entry types are supported:

**String entries** â€” content is already readable, embedded as-is:

```yaml
- id: knife_basics
  format: string
  category: "Techniques"
  heading: "Knife Skills"
  content: "The three essential cuts are dice, julienne, and chiffonade..."
```

**Object entries** â€” a template applied to each item:

```yaml
- id: cooking_temps
  format: object
  category: "Temperatures"
  heading: "Protein Cooking Temperatures"
  template: "{protein} cooked to {doneness}: internal temp {temp}Â°F. {notes}"
  items:
    - protein: "Chicken breast"
      doneness: "done"
      temp: "165"
      notes: "No pink remaining."
    - protein: "Beef steak"
      doneness: "medium-rare"
      temp: "130"
      notes: "Warm red center."
```

The chunker flattens object entries using the template, so each item becomes a standalone text chunk for embedding.

### Step 5: Generate embeddings

Run inside the Docker container so it hits LocalStack's DynamoDB and has all dependencies available:

```bash
docker compose exec api python -m ai.factory.core.generate_embeddings {bot_id}
```

This runs the full pipeline: chunker reads your YAML data, OpenAI converts each chunk to a 1,536-dimension vector, and the vectors are stored in the ChatbotRAG DynamoDB table tagged with your bot ID.

To regenerate after data changes:

```bash
docker compose exec api python -m ai.factory.core.generate_embeddings {bot_id} --force
```

The `--force` flag does a kill-and-fill scoped to your bot ID. Other bots' embeddings are untouched.

> **Note:** Do not run the embeddings command directly on your host machine (`python -m ai.factory...`). The dependencies (PyYAML, numpy, openai, etc.) are installed inside the container, not locally.

### Step 5b: Push embeddings to prod

Embeddings are generated against LocalStack locally. To push them to prod DynamoDB, use the export/import scripts in `ai/scripts/`. Both scripts take a `bot_id` argument to scope the operation â€” only that bot's embeddings are touched.

```bash
# Export one bot from LocalStack to _scratch/ (run inside container)
docker compose exec api python /app/ai/scripts/export_embeddings.py guitar

# Import one bot to prod DynamoDB (run from host)
python3 ai/scripts/import_embeddings.py guitar
```

The export saves to `_scratch/{bot_id}-embeddings-export.json` (already in `.gitignore`). The import deletes existing rows for that bot in prod, then writes the new ones. Other bots are untouched.

To export/import all bots at once:

```bash
docker compose exec api python /app/ai/scripts/export_embeddings.py --all
python3 ai/scripts/import_embeddings.py --all
```

> **Note:** Make sure `_scratch/` exists before exporting (`mkdir -p _scratch`). Run the import from your host machine where your AWS credentials are configured.

### Step 6: Scaffold the frontend

From the project root:

```bash
python3 ai/factory/scaffold_bot.py {bot_id}
```

This reads your config.yml and creates:

- `app/{bot_id}.html` â€” the bot's page, fully wired up
- `app/bot_scripts/{bot_id}/` â€” for bot-specific CSS and JS
- `app/assets/{bot_id}/` â€” for bot-specific images (logo, etc.)

After scaffolding, add your logo and any custom styles or formatters.

### Step 7: Test locally

```bash
docker compose up -d
```

Visit `http://localhost:8080/{bot_id}.html` and start chatting.

> **Tip:** If you update backend code (router, chatbot, retrieval), rebuild with `docker compose up --build -d`. Frontend file changes (HTML, JS, CSS) require a hard refresh (Ctrl+Shift+R) if cached.

### Step 8: Deploy

From the project root:

```bash
# 1. Push embeddings to prod (if data changed â€” see Step 5b)
docker compose exec api python /app/ai/scripts/export_embeddings.py {bot_id}
python3 ai/scripts/import_embeddings.py {bot_id}

# 2. Backend (Lambda)
./build-lambda.sh
aws s3 cp terraform/builds/fastapi-app.zip s3://aws-serverless-resume-prod/lambda/fastapi-app.zip
aws lambda update-function-code --function-name aws-serverless-resume-api --s3-bucket aws-serverless-resume-prod --s3-key lambda/fastapi-app.zip

# 3. Frontend (S3 + CloudFront)
aws s3 cp app/{bot_id}.html s3://aws-serverless-resume-prod/{bot_id}.html --cache-control "no-cache"
aws s3 cp app/bot_scripts/{bot_id}/ s3://aws-serverless-resume-prod/bot_scripts/{bot_id}/ --recursive --cache-control "no-cache"
aws s3 cp app/assets/{bot_id}/ s3://aws-serverless-resume-prod/assets/{bot_id}/ --recursive --cache-control "no-cache"
aws cloudfront create-invalidation --distribution-id <your_id> --paths "/*"
```

Skip step 1 if you only changed code or frontend files. Skip steps 2-3 if you only changed knowledge data.

## Project Structure

```
ai/factory/
â”œâ”€â”€ README.md                  â† you are here
â”œâ”€â”€ __init__.py                â† register_bots() auto-discovery
â”œâ”€â”€ scaffold_bot.py            â† frontend scaffolder
â”‚
â”œâ”€â”€ core/                      â† shared engine (never edit per-bot)
â”‚   â”œâ”€â”€ chunker.py             â† YAML â†’ text chunks
â”‚   â”œâ”€â”€ generate_embeddings.py â† chunks â†’ OpenAI â†’ DynamoDB
â”‚   â”œâ”€â”€ retrieval.py           â† question â†’ cosine search â†’ matches
â”‚   â”œâ”€â”€ chatbot.py             â† matches + question â†’ Claude â†’ response
â”‚   â””â”€â”€ router.py              â† creates FastAPI endpoints per bot
â”‚
â””â”€â”€ bots/                      â† one folder per bot
    â””â”€â”€ guitar/
        â”œâ”€â”€ config.yml         â† bot configuration
        â”œâ”€â”€ prompt.yml         â† system prompt for Claude
        â””â”€â”€ data/
            â””â”€â”€ guitar-knowledge.yml

app/                           â† frontend (generated by scaffold_bot.py)
â”œâ”€â”€ guitar.html                â† bot page
â”œâ”€â”€ bot_scripts/
â”‚   â”œâ”€â”€ bot-factory.css        â† shared framework styles
â”‚   â”œâ”€â”€ chat.js                â† shared chat module
â”‚   â”œâ”€â”€ navigation.js          â† shared nav highlighting
â”‚   â””â”€â”€ guitar/                â† bot-specific
â”‚       â”œâ”€â”€ guitar.css         â† custom styles (e.g., tab rendering)
â”‚       â””â”€â”€ formatter.js       â† custom message formatter (optional)
â””â”€â”€ assets/
    â””â”€â”€ guitar/                â† bot-specific images
        â””â”€â”€ logo.png
```

## Config Reference

### bot (required)

| Field         | Type    | Description                                                |
| ------------- | ------- | ---------------------------------------------------------- |
| `id`          | string  | Bot identifier. Drives folder names, endpoints, filenames. |
| `enabled`     | boolean | Set `false` to disable without deleting.                   |
| `name`        | string  | Display name (shown in header, chat labels).               |
| `personality` | string  | Personality hint for prompt context.                       |

### bot.response_style

| Field         | Type    | Description                                   |
| ------------- | ------- | --------------------------------------------- |
| `tone`        | string  | `"conversational"`, `"formal"`, `"technical"` |
| `length`      | string  | `"concise"`, `"detailed"`                     |
| `suggestions` | boolean | Show suggestion chips in the UI.              |

### bot.model

| Field        | Type    | Description                                  |
| ------------ | ------- | -------------------------------------------- |
| `provider`   | string  | `"anthropic"`                                |
| `name`       | string  | Model ID, e.g., `"claude-sonnet-4-20250514"` |
| `max_tokens` | integer | Max response length.                         |

### bot.rag

| Field                  | Type    | Description                                                             |
| ---------------------- | ------- | ----------------------------------------------------------------------- |
| `embedding_model`      | string  | `"openai"` (uses text-embedding-3-small)                                |
| `top_k`                | integer | Number of chunks to retrieve. Use 10+ if data has many similar entries. |
| `similarity_threshold` | float   | Minimum cosine similarity (0.0â€“1.0).                                    |

### bot.boundaries

Free-form key-value pairs. The keys are used in the system prompt to define what the bot will and won't discuss. Name them whatever makes sense for your bot.

### suggestions (required)

List of starter questions shown as chips in the chat UI.

### frontend (required for scaffold)

| Field         | Type   | Description                                                   |
| ------------- | ------ | ------------------------------------------------------------- |
| `subtitle`    | string | Shown below the bot name in the header.                       |
| `welcome`     | string | First message displayed in the chat.                          |
| `placeholder` | string | Input field hint text.                                        |
| `badge`       | string | Header badge text (e.g., "Beta", "v1").                       |
| `nav`         | list   | Left sidebar links. Each item has `icon`, `label`, `section`. |

## Custom Formatters

The shared `chat.js` supports a plugin hook for bot-specific message rendering. If your bot outputs content that needs special formatting (like guitar tablature), create a `formatter.js` in your bot's `bot_scripts/{bot_id}/` folder.

The formatter registers itself on `window.BOT_CONFIG.formatMessage`:

```javascript
function myFormatMessage(text, container) {
  // custom rendering logic
}

window.BOT_CONFIG = window.BOT_CONFIG || {};
window.BOT_CONFIG.formatMessage = myFormatMessage;
```

Load it in your HTML **after** the BOT_CONFIG block and **before** chat.js:

```html
<script>
  window.BOT_CONFIG = { ... };
</script>
<script src="bot_scripts/{bot_id}/formatter.js"></script>
<script src="bot_scripts/chat.js"></script>
```

If no formatter is registered, `chat.js` uses its default plain text renderer.

## Auto-Discovery

The factory uses auto-discovery in `__init__.py`. At startup, it scans every folder in `bots/`, reads each `config.yml`, and registers API routes for any bot with `enabled: true`. Adding a new bot never requires editing `main.py`.

Each bot gets three endpoints:

- `POST /api/{bot_id}/chat` â€” send a message, get a response
- `GET /api/{bot_id}/config` â€” frontend configuration
- `GET /api/{bot_id}/warmup` â€” pre-load embedding cache

## Existing Bots

| Bot                | ID       | Endpoint           | Description                                                                  |
| ------------------ | -------- | ------------------ | ---------------------------------------------------------------------------- |
| RobbAI             | â€”        | `/api/ai/chat`     | Resume assistant. Runs on legacy code in `ai/`, not yet migrated to factory. |
| The Fret Detective | `guitar` | `/api/guitar/chat` | Electric guitar instruction. First factory bot.                              |

## Embedding Notes

All bot embeddings share one DynamoDB table (`ChatbotRAG`), partitioned by bot ID. Each record's primary key is `{bot_id}_{entry_id}` and includes a `bot_id` field for filtering.

The kill-and-fill approach on `--force` only deletes rows matching the target bot ID. Running embeddings for one bot never affects another.

If your bot has many similar entries (like The Fret Detective's 48 triad voicings), increase `top_k` in your config to 10 or higher so the right result isn't crowded out by near-duplicates.
